# 音视频基本原理

- [音视频基本原理](#音视频基本原理)
  - [流媒体收发过程](#流媒体收发过程)
  - [视频主要概念](#视频主要概念)
  - [视频编码基础](#视频编码基础)
    - [数据冗余](#数据冗余)
    - [视频帧预测](#视频帧预测)
    - [DCT变换和量化](#dct变换和量化)
  - [图像缩放](#图像缩放)
    - [插值算法](#插值算法)
    - [AI超分算法](#ai超分算法)
  - [音频主要概念](#音频主要概念)
  - [封装概念](#封装概念)
  - [音视频同步](#音视频同步)

## 流媒体收发过程

![音视频录制原理](https://github.com/gongluck/images/blob/main/av/流媒体收发过程.png)

## 视频主要概念

![视频基础](https://github.com/gongluck/images/blob/main/av/video_base.png)
![视频帧类型](https://github.com/gongluck/images/blob/main/av/视频帧类型.png)

- **视频码率**：**kb/s**，是指视频文件在单位时间内使用的数据流量，也叫码流率。码率越大，说明单位时间内取样率越大，数据流精度就越高。
- **视频帧率**：**fps**，通常说一个视频的25帧，指的就是这个视频帧率，即1秒中会显示25帧。帧率越高，给人的视觉就越流畅。
- **视频分辨率**：分辨率就是我们常说的640x480分辨率、1920x1080分辨率，分辨率影响视频图像的大小。
- **Stride**：跨距，是图像存储的时候有的一个概念。它指的是图像存储时内存中每行像素所占用的空间。
  ![跨距](https://github.com/gongluck/images/blob/main/av/stride.png)
- **I** 帧（**Intra coded frames**）：
  - I帧不需要参考其他画面而生成，解码时仅靠自己就重构完整图像；
  - I帧图像采用帧内编码方式；
  - I帧所占数据的信息量比较大；
  - I帧图像是周期性出现在图像序列中的，出现频率可由编码器选择；
  - I帧是P帧和B帧的参考帧（其质量直接影响到同组中以后各帧的质量）；
  - **IDR** 帧是帧组GOP的基础帧（第一个（I）帧），在一组GOP中只有一个IDR帧；
  - I帧不需要考虑运动矢量；
- **P** 帧（**Predicted frames**）根据本帧与相邻的前一帧（I帧或P帧）的不同点来压缩本帧数据，同时利用了空间和时间上的相关性。
- P帧属于前向预测的帧间编码。它需要参考前面最靠近它的 **I** 帧或 **P** 帧来解码。
- **B** 帧（**Bi-directional predicted frames**）采用双向时间预测，可以大大提高压缩倍数。

## 视频编码基础

- 先通过 **帧内预测** 或者 **帧间预测** 去除 **空间冗余** 和 **时间冗余** ，从而得到一个像素值相比编码块小很多的 **残差块** 。
- 再通过 **DCT** 变换将低频和高频信息分离开来得到变换块，然后再对变换块的系数做 **量化**。由于高频系数（变化频率大）通常比较小，很容易量化为 0，同时 **人眼对高频信息不太敏感** ，这样我们就得到了一串含有很多个 0，大多数情况下是一串含有连续 0 的“像素串”，并且人的观感还不会太明显。
- 最后 **熵编码** 就能把图像压缩成比较小的数据，以此达到视频压缩的目的。这就是视频编码的原理

### 数据冗余

图像一般都是有数据冗余的，主要包括以下 4 种：

- **空间冗余** 比如说将一帧图像划分成一个个 ```16x16``` 的块之后，相邻的块很多时候都有比较明显的相似性，这种就叫空间冗余。
- **时间冗余** 一个帧率为 ```25fps``` 的视频中前后两帧图像相差只有 ```40ms```，两张图像的变化是比较小的，相似性很高，这种叫做时间冗余。
- **视觉冗余** 我们的眼睛是有视觉灵敏度这个东西的。人的眼睛对于图像中高频信息的敏感度是小于低频信息的。有的时候去除图像中的一些高频信息，人眼看起来跟不去除高频信息差别不大，这种叫做视觉冗余。
- **信息熵冗余** 我们一般会使用 ```Zip``` 等压缩工具去压缩文件，将文件大小减小，这个对于图像来说也是可以做的，这种冗余叫做信息熵冗余。

### 视频帧预测

图像内部相邻宏块之间有很多 **相似性** ，并且两张图像之间也有很多 **相似性** 。因此，根据图像的这个特点，我们可以在编码的时候进行 **帧内预测** 和 **帧间预测** 。

通过预测得到的 **残差块** 的像素值相比 **编码块** 的像素值，去除了大部分 **空间冗余** 信息和 **时间冗余** 信息，这样得到的像素值更小。如果把这个残差块做扫描得到的像素串送去做行程编码，相比直接拿编码块的像素串去做编码更有可能得到更大的 **压缩率** 。

- 帧内预测

  ![帧内预测](https://github.com/gongluck/images/blob/main/av/帧内预测.png)
  ![帧内预测类型](https://github.com/gongluck/images/blob/main/av/帧内预测类型.png)

  - 在当前编码图像内部已经编码完成的块中找到与将要编码的块相邻的块。一般就是即将编码块的左边块、上边块、左上角块和右上角块，通过将这些块与编码块相邻的像素经过多种不同的算法得到多个不同的预测块。然后我们再用 **编码块** 减去每一个 **预测块** 得到一个个 **残差块** 。最后，我们取这些算法得到的残差块中像素的绝对值加起来最小的块为预测块。而得到这个预测块的算法为 **帧内预测模式** 。
  - 一幅图像中相邻像素的亮度和色度信息是比较接近的，并且亮度和色度信息也是逐渐变化的，不太会出现突变。也就是说，图像具有 **空间相关性** 。帧内预测通过利用已经编码的相邻像素的值来预测待编码的像素值，最后达到减少空间冗余的目的。已经编码的块会解码成像素用来做参考像素。
  - 在 ```H264``` 标准里面，块分为宏块和子块。宏块的大小是 16 x 16（YUV 4:2:0 图像亮度块为 16 x 16，色度块为 8 x 8）。在帧内预测中，亮度宏块可以继续划分成 16 个 4 x 4 的子块。因为图像中有的地方细节很多，我们需要划分成更小的块来做预测会更精细，所以会将宏块再划分成 4 x 4 的子块。

- 帧间预测

  - 在前面已经编码完成的图像中，循环遍历每一个块，将它作为预测块，用当前的编码块与这个块做差值，得到 **残差块** ，取残差块中像素值的绝对值加起来最小的块为 **预测块** ，预测块所在的已经编码的图像称为 **参考帧** 。预测块在参考帧中的坐标值 (x0, y0) 与编码块在编码帧中的坐标值 (x1, y1) 的差值 (x0 - x1, y0 - y1) 称之为 **运动矢量** 。而在参考帧中去寻找预测块的过程称之为 **运动搜索** 。
  - 前后两帧图像往往变化比较小，这就是视频的 **时间相关性** 。帧间预测就是利用这个特点来进行的。通过在已经编码的帧里面找到一个块来预测待编码块的像素，从而达到减少时间冗余的目的。
  - 只参考前面图像的帧我们称为 **前向参考帧**，也叫 **P 帧** ；参考后面的图像或者前面后面图像都参考的帧，我们称之为 **双向参考帧** ，也叫做 **B 帧** 。B 帧相比 P 帧主要是需要先编码后面的帧，并且 B 帧一个编码块可以有两个预测块，这两个预测块分别由两个参考帧预测得到，最后加权平均得到最终的预测块。
  - 在 ```H264``` 标准中，P 帧最多支持从 16 个参考帧中选出一个作为编码块的参考帧，但是同一个帧中的不同块可以选择不同的参考帧，这就是 **多参考** 。

- 运动搜索

  - 用运动矢量来表示编码帧中编码块和参考帧中的预测块之间的位置的差值。使用运动矢量就可以在参考帧中找到预测块。
  - 从参考帧中第一个像素开始，将一个个 16 x 16 大小的块都遍历一遍。我们总是可以找到差距最小的块。这种方法我们称之为 **全搜索算法** 。
  - **亚像素精度运动搜索**
    - 先通过快速搜索算法进行整像素运动搜索算法得到整像素的运动矢量。
    - 对参考帧进行半像素和 1/4 像素插值。以整像素运动矢量指向的整像素为起点，进行钻石搜索算法，分别求得中心点以及上、下、左、右四个半像素点对应预测块的残差块，得到 SAD 值。取 SAD 值最小的点为最佳匹配点。
    - 以半像素运动搜索的最佳匹配点为起点，分别求得中心点以及上、下、左、右四个 1/4 像素点对应预测块的残差块，得到 SAD 值，并取最小的点为最佳匹配点。
  - 运动矢量跟我们的编码块一样不是直接编码进去的，而是先用周围相邻块的运动矢量预测一个预测运动矢量，称为 MVP。将当前运动矢量与 MVP 的残差称之为 MVD，然后编码到码流中去的。解码端使用同样的运动矢量预测算法得到 MVP，并从码流中解码出运动矢量残差 MVD，MVP+MVD 就是运动矢量了。
  - P 帧中的静止部分，前后两帧不会变化，运动矢量直接为 0，而且残差块像素值本身因为几乎没有变化基本为 0，只有少部分噪声引起的比较小的值，量化后更是全部变成了 0。这种图像中的静止部分或者是图像中的背景部分大多数时候都是 **SKIP** 模式。这种模式非常省码率，且压缩效率非常高。
  - **参考帧** 和 **运动矢量** 。在 **RTC** 场景中我们一般选择 **单参考** ，并且一般选择当前编码图像的前一帧作为参考帧。**运动矢量是用来表示参考帧中预测块与编码帧中编码块位置的相对距离的** 。
  - 运动矢量是通过运动搜索得到的，而 **运动搜索** 是在 **参考帧** 中进行的。通常我们会使用 **钻石搜索** 和 **六边形搜索** 等 **快速运动搜索** 算法。一般不会使用全搜索算法。其中钻石搜索算法更简单，步骤更少，所以如果需要编码速度快，一般选择钻石搜索。六边形搜索步骤更多，更精细，要求编码质量高，同时对速度要求不高的时候，可以选择六边形搜索。
  - 为了能够更准确的找到预测块，我们可以将 16 x 16 的宏块继续划分成更小的子块来做运动搜索。因为图像有的地方静止的背景画面或者平坦的区域可以直接选用最大的块来搜索预测块；而有的地方细节很多，图像中的物体运动方向也各不相同，可能就需要划分成更小的块来做运动搜索。这样每一个块都拥有自己独立的运动矢量，并且得到的预测块更接近于编码块，从而有利于提高压缩效率。
  - 光做整像素运动搜索不太能够准确的处理连续运动场景。为了能够处理好这种连续运动的问题，我们对参考帧进行亚像素插值得到半像素和 1/4 像素图像。然后在整像素搜索的基础上在亚像素图像上做亚像素精度的运动搜索。实验数据证明，半像素和 1/4 像素精度的运动搜索相比整像素精度的运动搜索可以明显地提高压缩效率。

### DCT变换和量化

- ```DCT``` 变换，就是 **离散余弦变换** 。它能够将空域的信号（对于图像来说，空域就是你平时看到的图像）转换到频域（对于图像来说，就是将图像做完 DCT 变换之后的数据）上表示，并能够比较好的去除相关性。其主要用于视频压缩领域。现在常用的视频压缩算法中基本上都有 DCT 变换。
- 图片经过 DCT 变换之后，低频信息集中在左上角，而高频信息则分散在其它的位置。通常情况下，图片的高频信息多但是幅值比较小。高频信息主要描述图片的边缘信息。
- 由于人眼的视觉敏感度是有限的，有的时候我们去除了一部分高频信息之后，人眼看上去感觉区别并不大。因此，我们可以先将图片 DCT 变换到频域，然后再去除一些高频信息。这样我们就可以减少信息量，从而达到压缩的目的。**DCT 变换本身是无损的，同时也是可逆的**。我们可以通过 DCT 变换将图片从空域转换到频域，也可以通过 DCT 反变换将图片从频域转回到空域。
- **在视频压缩中，DCT 变换是在帧内预测和帧间预测之后进行的**。也就是说，DCT 变换其实是对残差块做的。我们在编码时会将图像划分成一个个宏块，而宏块又可以划分成一个个子块。
- **通常 QStep 值越大，DC 系数和 AC 系数被量化成 0 的概率也就越大，从而压缩程度就越大，但是丢失的信息也就越多**。这个值太大了会造成视频出现一个个块状的效应，且严重的时候看起来像马赛克一样；这个值比较小的话，压缩程度也会比较小，从而图像失真就会比较小，但是压缩之后的码流大小就会比较大。
- 量化其实就是一个除法操作。通过除法操作就可以将幅值变小，而高频信息幅值比较小，就比较容易被量化成 0，这样就能够达到压缩的目的。
- 在 H264 标准中，我们不会直接使用标准的 DCT 变换和量化。为了减少多次浮点型运算在解码端产生漂移的问题，H264 使用整数变换代替 DCT 变换。DCT 变换中的浮点运算部分跟量化过程进行合并，将两次浮点型运算变成一次，从而减少误差。

## 图像缩放

图像的缩放就是将原图像的已有像素经过 **加权** 运算得到目标图像的目标像素。

![放大](https://github.com/gongluck/images/blob/main/av/图像缩放/scale_large.png)
![缩小](https://github.com/gongluck/images/blob/main/av/图像缩放/scale_small.png)

### 插值算法

![插值算法](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/插值算法.png)

- 最近邻插值

  ![最近邻插值](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/最近邻插值/最近邻插值.png)

  最近邻插值有一个明显的缺点 -- **结果图像变化不平滑**，就是它直接使用离插值位置最近的整数位置的像素作为插值像素，这样会导致相邻两个插值像素有很大的概率是相同的。这样得到的放大图像大概率会出现块状效应，而缩小图像容易出现锯齿。这是最近邻插值的缺点。但是它也有一个优点，就是不需要太多的计算，速度非常的快。

- 双线性插值

  ![双线性插值](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/双线性插值/双线性插值.png)

  双线性插值需要将周围4个像素值通过一定的运算得到最后的插值像素。

  ![线性插值计算](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/双线性插值/线性插值计算.png)
  
  线性插值是一种以距离作为权重的插值方式，距离越近权重越大，距离越远权重越小。

  ![双线性插值计算](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/双线性插值/双线性插值计算.png)

  双线性插值本质上就是在两个方向上做线性插值，是三次线性插值的过程。

- 双三次插值(BiCubic)

  ![双三次插值](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/双三次插值/双三次插值.png)
  ![双三次插值计算](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/双三次插值/双三次插值计算.png)

  双三次插值需要计算16个点的权重再乘以像素值求和。

  ![BiCubic基函数](https://github.com/gongluck/images/blob/main/av/图像缩放/插值算法/双三次插值/BiCubic基函数.png)
  
  周围像素的权重计算是使用一个特殊的BiCubic基函数来计算的。

### AI超分算法

## 音频主要概念

- **采样频率**：每秒钟采样的点的个数。常用的采样频率有：
  |      采样率      |   常见用途    |
  | :--------------: | :-----------: |
  |  22000（22kHz）  |   无线广播    |
  | 44100（44.1kHz） |    CD音质     |
  |  48000（48kHz）  | 数字电视，DVD |
  |  96000（96kHz）  | 蓝光，高清DVD |
  | 192000（192kHz） | 蓝光，高清DVD |
- **采样精度（采样深度）**：每个“样本点”的大小，常用的大小为8bit， 16bit，24bit。
- **通道数**：单声道，双声道，四声道，5.1声道。
- **比特率**：每秒传输的bit数，单位为：bps（Bit Per Second）。间接衡量声音质量的一个标准。没有压缩的音频数据的比特率 = 采样频率 * 采样精度 * 通道数。
- **码率**：压缩后的音频数据的比特率。常见的码率：
  |    码率     |   常见用途   |
  | :---------: | :----------: |
  |   96kbps    |    FM质量    |
  | 128-160kbps | 一般质量音频 |
  |   192kbps   |    CD质量    |
  | 256-320Kbps |  高质量音频  |
  - 码率越大，压缩效率越低，音质越好，压缩后数据越大。
  - 码率 = 音频文件大小 / 时长。
- **帧**：每次编码的采样单元数，比如 **MP3** 通常是 **1152** 个采样点作为一个编码单元，**AAC** 通常是 **1024** 个采样点作为一个编码单元。
- **帧长**：可以指每帧播放持续的时间。每帧持续时间（秒）= 每帧采样点数 / 采样频率（HZ）。比如：MP3 48k，1152个采样点，每帧则为24毫秒，1152/48000 = 0.024秒 = 24毫秒；也可以指压缩后每帧的数据长度。
- **交错模式**：数字音频信号存储的方式。数据以连续帧的方式存放，即首先记录帧1的左声道样本和右声道样本，再开始帧2的记录...
- **非交错模式**：首先记录的是一个周期内所有帧的左声道样本，再记录所有右声道样本。
- 数字音频压缩编码在保证信号在听觉方面不产生失真的前提下，对音频数据信号进行尽可能大的压缩，降低数据量。数字音频压缩编码采取去除声音信号中冗余成分的方法来实现。所谓冗余成分指的是音频中不能被人耳感知到的信号，它们对确定声音的音色，音调等信息没有任何的帮助。

## 封装概念

- **封装格式**（也叫容器）就是将已经编码压缩好的视频流、音频流及字幕按照一定的方案放到一个文件中，便于播放软件播放。
- **一般来说，视频文件的后缀名就是它的封装格式。**
- **封装的格式不一样，后缀名也就不一样。**

## 音视频同步

- **DTS**（**Decoding Time Stamp**）：即解码时间戳，这个时间戳的意义在于告诉播放器该在什么时候解码这一帧的数据。
- **PTS**（**Presentation Time Stamp**）：即显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据。
- **音视频同步方式：**
  |         名称          |           实现           |
  | :-------------------: | :----------------------: |
  |     Audio Master      |      同步视频到音频      |
  |     Video Master      |      同步音频到视频      |
  | External Clock Master | 同步音频和视频到外部时钟 |
  - 一般情况下选择：Audio Master > External Clock Master > Video Master
